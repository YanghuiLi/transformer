{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotated Transformer\n",
    "\n",
    "* http://nlp.seas.harvard.edu/2018/04/03/attention.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-16 23:35:07,938 - transformer - INFO - logger test - info\n",
      "2018-10-16 23:35:07,939 - transformer - DEBUG - logger test - debug\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "sys.path.append(\"../python/\")\n",
    "from transformer import *\n",
    "\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-10-16 23:35:11,992 - transformer - INFO - test info\n",
      "2018-10-16 23:35:11,994 - transformer - DEBUG - test debug\n"
     ]
    }
   ],
   "source": [
    "dummy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(V, batch, nbatches, in_seq_len, ctx = mx.cpu()):\n",
    "    \"Generate random data for a src-trg copy task.\"\n",
    "    for i in range(nbatches):\n",
    "        data = nd.array(np.random.randint(1, V, size=(batch, in_seq_len)), ctx =ctx)\n",
    "        data[:, 0] = 1\n",
    "        src, trg = data, data\n",
    "        yield Batch(src, trg, 0, ctx)\n",
    "\n",
    "V = 11\n",
    "data = data_gen(V, 30, 50, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: copy 10 input integers\n",
    "V = 20\n",
    "batch = 30\n",
    "n_batch = 20\n",
    "in_seq_len = 10\n",
    "out_seq_len = 9\n",
    "dropout = .1\n",
    "data = data_gen(V, batch, n_batch, in_seq_len)\n",
    "model = make_model(V, V, in_seq_len, out_seq_len, N=2, dropout = .1, ctx = ctx)\n",
    "model.collect_params().initialize(mx.init.Xavier(), ctx = ctx)\n",
    "trainer = gluon.Trainer(model.collect_params(), 'adam', {'learning_rate': 1e-9, 'beta1': 0.9, 'beta2': 0.98 , 'epsilon': 1e-9})\n",
    "loss = gluon.loss.KLDivLoss(from_logits = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(1):\n",
    "    run_epoch(data_gen(V, batch, n_batch, in_seq_len, ctx = ctx), model, trainer, loss, ctx = ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = \n",
      "[[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]]\n",
      "<NDArray 1x10 @gpu(0)>\n",
      "out = (1, 1, 20)\n",
      "out = (1, 2, 20)\n",
      "out = (1, 3, 20)\n",
      "out = (1, 4, 20)\n",
      "out = (1, 5, 20)\n",
      "out = (1, 6, 20)\n",
      "out = (1, 7, 20)\n",
      "out = (1, 8, 20)\n",
      "out = (1, 9, 20)\n",
      "tgt = \n",
      "[[ 1. 17. 17. 17. 17. 17. 17. 17. 17. 17.]]\n",
      "<NDArray 1x10 @gpu(0)>\n"
     ]
    }
   ],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = nd.array([[start_symbol]], ctx = ctx)\n",
    "    for i in range(max_len-1):\n",
    "        out = model.decode(memory, src_mask, ys, subsequent_mask(ys.shape[1]))\n",
    "        print('out = {}'.format(out.shape))\n",
    "        #print('prob = {}'.format(out))\n",
    "        next_word = nd.argmax(out, axis = 2)\n",
    "        #print('i = {}, next_word = {}, last word = {}'.format(i, next_word.shape, next_word[:,-1].expand_dims(axis = 1).shape))\n",
    "        #print('i = {}, ys = {}'.format(i, ys.shape))\n",
    "        ys = nd.concat(ys, next_word[:,-1].expand_dims(axis = 1), dim = 1)\n",
    "        #ys = next_word\n",
    "    return ys\n",
    "\n",
    "src = nd.array([[1,2,3,4,5,6,7,8,9,10]], ctx = ctx)\n",
    "print('src = {}'.format(src))\n",
    "src_mask = nd.ones_like(src)\n",
    "with autograd.predict_mode():\n",
    "    res = greedy_decode(model, src, src_mask, max_len=10, start_symbol=1)\n",
    "print('tgt = {}'.format(res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
