# Transformer

A network only contains attention mechanism without underlying recurrent network. It solved speed issue and bottleneck issue of RNNs.


# Usage

```
python ./python/transformer.py -s 6,2,3,4,5,3,3,1
```
